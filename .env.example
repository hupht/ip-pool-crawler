# ==============================================
# 数据库配置 - MySQL
# ==============================================
MYSQL_HOST=127.0.0.1          # MySQL 服务器地址（本地使用 127.0.0.1 或 localhost）
MYSQL_PORT=3306               # MySQL 服务端口（默认 3306）
MYSQL_USER=root               # MySQL 用户名（生产环境建议使用专用账号）
MYSQL_PASSWORD=               # MySQL 密码（请填写实际密码，留空表示无密码）
MYSQL_DATABASE=ip_pool        # 数据库名称（如不存在会自动创建）

# ==============================================
# 数据库配置 - Redis
# ==============================================
REDIS_HOST=127.0.0.1          # Redis 服务器地址（本地使用 127.0.0.1）
REDIS_PORT=6379               # Redis 服务端口（默认 6379）
REDIS_DB=0                    # Redis 数据库编号（0-15，建议使用专用 DB 避免冲突）
REDIS_PASSWORD=               # Redis 密码（留空表示无密码认证）

# ==============================================
# API 服务器配置
# ==============================================
API_HOST=0.0.0.0              # API 服务器监听地址（0.0.0.0=所有接口，127.0.0.1=仅本地）
API_PORT=8000                 # API 服务器监听端口（默认 8000，建议 8000-9000）

# ==============================================
# HTTP 请求配置
# ==============================================
HTTP_TIMEOUT=10               # HTTP 请求超时时间（秒），范围 5-30，慢速源建议 15-30
HTTP_RETRIES=1                # HTTP 请求失败重试次数，建议 1-3 次
USER_AGENT=ip-pool-crawler/0.1  # User-Agent 字符串，建议模拟常见浏览器避免反爬

# ==============================================
# 并发控制配置
# ==============================================
SOURCE_WORKERS=2              # 并发抓取数据源数量（1-10），受限于网络带宽
VALIDATE_WORKERS=30           # 并发验证代理数量（10-100），受限于网络连接数

# ==============================================
# 代理检查配置
# ==============================================
CHECK_BATCH_SIZE=1000         # 每批次检查的代理数量（建议 500-2000）
CHECK_WORKERS=20              # 并发检查线程数（建议 10-50）
CHECK_RETRIES=3               # 检查失败重试次数（建议 2-5）
CHECK_RETRY_DELAY=3           # 重试间隔（秒），避免频繁请求
FAIL_WINDOW_HOURS=24          # 失败窗口时长（小时），代理连续失败的监控周期
FAIL_THRESHOLD=5              # 失败次数阈值，达到后标记为不可用（建议 3-10）

# ==============================================
# 日志配置 - 基础设置
# ==============================================
LOG_LEVEL=INFO                # 日志级别：DEBUG|INFO|WARNING|ERROR（生产环境推荐 INFO）
LOG_FILE_PATH=./logs/crawler.log        # 日志文件路径（相对于项目根目录）
LOG_FILE_MAX_SIZE_MB=100      # 单个日志文件最大大小（MB），超过后自动轮转
LOG_FILE_BACKUP_COUNT=10      # 保留的历史日志文件数量
LOG_DB_WRITE_ENABLED=true     # 是否将日志写入数据库（audit_logs 表）

# ==============================================
# 日志配置 - 敏感信息脱敏
# ==============================================
LOG_DB_MASK_SENSITIVE=true    # 数据库日志是否脱敏（IP、密码等敏感信息）
LOG_FILE_MASK_SENSITIVE=false # 文件日志是否脱敏（建议：生产环境 true，开发环境 false）

# ==============================================
# 日志配置 - 保留策略
# ==============================================
LOG_DB_RETENTION_DAYS=30      # 数据库日志保留天数（超过自动清理）
LOG_ARCHIVE_PATH=./logs/archive  # 归档日志存储路径

# ==============================================
# 通用动态爬虫配置
# ==============================================
DYNAMIC_CRAWLER_ENABLED=true  # 是否启用动态爬虫功能（true|false）

# ----------------------------------------------
# 启发式检测配置
# ----------------------------------------------
HEURISTIC_CONFIDENCE_THRESHOLD=0.5  # 启发式解析置信度阈值（0-1），低于此值触发 AI
MIN_EXTRACTION_COUNT=3        # 最小提取数量，少于此数量视为解析失败
ENABLE_STRUCT_AWARE_PARSING=true    # 是否启用结构感知解析（智能识别表格/JSON）

# ----------------------------------------------
# 分页控制配置
# ----------------------------------------------
MAX_PAGES=5                   # 单次爬取最大页数限制（防止无限爬取）
MAX_PAGES_NO_NEW_IP=3         # 连续无新 IP 页数阈值（达到后自动停止）
CROSS_PAGE_DEDUP=true         # 是否跨页去重（避免重复抓取相同代理）
PAGE_FETCH_TIMEOUT_SECONDS=10 # 单页抓取超时时间（秒）

# ==============================================
# LLM（大语言模型）配置 - 用户需自主填写
# ==============================================
# 是否启用 AI 辅助解析（默认 false，需用户显式启用）
USE_AI_FALLBACK=false         # 启用后，复杂页面自动调用 LLM 辅助解析

# ----------------------------------------------
# LLM 服务配置（支持自定义 API）
# ----------------------------------------------
# 示例：OpenAI 官方 API
LLM_BASE_URL=https://api.openai.com/v1  # API 基础 URL（可替换为其他兼容服务）
LLM_MODEL=gpt-4o-mini         # 模型名称：gpt-4o-mini（推荐）| gpt-4-turbo | gpt-3.5-turbo
LLM_API_KEY=sk-your-key-here  # API 密钥（请替换为实际密钥）

# 支持其他 LLM 提供商（仅需修改 LLM_BASE_URL）：
# - Azure OpenAI: https://your-resource.openai.azure.com/
# - 本地 Ollama: http://localhost:11434/v1
# - DeepSeek: https://api.deepseek.com/v1
# - 其他兼容 OpenAI API 格式的服务

LLM_TIMEOUT_SECONDS=30        # LLM API 请求超时时间（秒），建议 20-60
LLM_MAX_RETRIES=3             # LLM API 请求失败重试次数

# ----------------------------------------------
# LLM 提示词配置（自定义 AI 行为）
# ----------------------------------------------
# 系统提示词：定义 AI 角色和基本行为规则
LLM_SYSTEM_PROMPT=你是资深代理数据抽取器。仅输出合法 JSON，不要输出解释、Markdown 或额外文本。

# 用户提示词模板：具体任务描述（支持变量 {context_json} 和 {html_snippet}）
LLM_USER_PROMPT_TEMPLATE=任务：从 HTML 中提取代理列表，并严格返回 JSON。\n规则：\n1) 仅提取公网 IPv4，过滤私网/保留地址。\n2) port 必须是 1-65535 的整数。\n3) protocol 统一为 http/https/socks4/socks5，未知时用 http。\n4) confidence 取值 0-1。\n5) 按 ip+port+protocol 去重。\n6) 若未提取到结果，返回 {"proxies":[]}。\n输出要求：仅输出 JSON 对象，格式为 {"proxies":[{"ip":"...","port":8080,"protocol":"http","confidence":0.95}]}。\n上下文：{context_json}\nHTML：\n{html_snippet}

# ----------------------------------------------
# HTML 提交策略配置
# ----------------------------------------------
# 是否提交完整 HTML 给 LLM（true=完整页面，false=仅提交片段）
LLM_SUBMIT_FULL_HTML=false    # false 可节省 token 成本，但可能影响提取效果

# 当 LLM_SUBMIT_FULL_HTML=false 时生效，提交前 N 个字符
# ⚠️ 注意：提交字符越少，提取效果通常越差（上下文不足）
LLM_HTML_SNIPPET_CHARS=5000   # 建议 3000-10000，按实际页面结构调整

# ==============================================
# AI 触发条件配置（何时调用 LLM）
# ==============================================
AI_TRIGGER_ON_LOW_CONFIDENCE=true   # 启发式解析置信度低时触发 AI
AI_TRIGGER_ON_NO_TABLE=true         # 页面无表格结构时触发 AI
AI_TRIGGER_ON_FAILED_PARSE=true     # 常规解析完全失败时触发 AI
AI_TRIGGER_ON_USER_REQUEST=true     # 用户明确要求使用 AI 时（--use-ai 参数）

# ==============================================
# AI 缓存配置（减少重复调用成本）
# ==============================================
AI_CACHE_ENABLED=true         # 是否启用 LLM 调用结果缓存
AI_CACHE_TTL_HOURS=24         # 缓存有效期（小时），建议 24-168（7天）

# ==============================================
# AI 成本控制
# ==============================================
AI_COST_LIMIT_USD=100         # AI 调用成本上限（美元），超过后拒绝调用

# ==============================================
# 错误处理配置
# ==============================================
ERROR_RECOVERY_MODE=retry     # 错误恢复模式：retry（重试）| skip（跳过）| fail（终止）
MAX_RETRIES_PER_PAGE=3        # 单页面最大重试次数
RETRY_BACKOFF_SECONDS=5       # 重试退避时间（秒），每次重试前等待
SAVE_FAILED_PAGES_SNAPSHOT=true  # 是否保存失败页面的快照（用于调试）

# ==============================================
# 人工审查队列配置
# ==============================================
REQUIRE_MANUAL_REVIEW=false   # 是否要求所有结果人工审查（true=全部进队列）
SAVE_LOW_CONFIDENCE_DATA=true # 是否保存低置信度数据到审查队列
LOW_CONFIDENCE_THRESHOLD=0.5  # 低置信度阈值（0-1），低于此值进入审查队列

# ==============================================
# 动态爬虫日志级别
# ==============================================
DYNAMIC_CRAWLER_LOG_LEVEL=INFO  # 动态爬虫独立日志级别：DEBUG|INFO|WARNING|ERROR
