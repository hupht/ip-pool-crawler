# ç”Ÿäº§éƒ¨ç½²æŒ‡å—

å®Œæ•´çš„ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€é…ç½®å’ŒéªŒè¯æ¸…å•ã€‚

## ğŸ“‹ éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

### å‰ç½®ç¯å¢ƒè¦æ±‚

- [ ] Python 3.10+ å·²å®‰è£…
- [ ] MySQL 5.7+ å·²å®‰è£…ä¸”æ­£åœ¨è¿è¡Œ
- [ ] Redis 3.0+ å·²å®‰è£…ä¸”æ­£åœ¨è¿è¡Œ
- [ ] æœåŠ¡å™¨æœ‰ 10GB+ å¯ç”¨ç£ç›˜ç©ºé—´
- [ ] æœåŠ¡å™¨æœ‰ 2GB+ å¯ç”¨å†…å­˜
- [ ] ç½‘ç»œèƒ½è®¿é—®ä»£ç†æºï¼ˆgeonode.com ç­‰ï¼‰

### éªŒè¯ç¯å¢ƒ

```bash
# Python ç‰ˆæœ¬
python --version                 # åº” >= 3.10

# MySQL è¿æ¥
mysql -h 127.0.0.1 -u root -p -e "SELECT VERSION();"

# Redis è¿æ¥
redis-cli PING                   # åº”è¿”å› PONG

# ç½‘ç»œè¿é€šæ€§
curl -I https://proxylist.geonode.com
```

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤ 1: è·å–ä»£ç 

```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
git clone https://github.com/your-repo/ip-pool-crawler.git
cd ip-pool-crawler

# æˆ–è§£å‹å‹ç¼©åŒ…
unzip ip-pool-crawler.zip
cd ip-pool-crawler
```

### æ­¥éª¤ 2: å®‰è£…ä¾èµ–

```bash
# å¸¸è§„å®‰è£…
pip install -r requirements.txt

# ä½¿ç”¨å›½å†…æºåŠ é€Ÿï¼ˆå¯é€‰ï¼‰
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
```

**éªŒè¯å®‰è£…**ï¼š
```bash
python -c "import requests, pymysql, redis; print('âœ“ ä¾èµ–å®‰è£…æˆåŠŸ')"
```

### æ­¥éª¤ 3: é…ç½®ç¯å¢ƒ

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼š

```dotenv
# ============ MySQL é…ç½® ============
MYSQL_HOST=192.168.1.100        # MySQL æœåŠ¡å™¨åœ°å€
MYSQL_PORT=3306
MYSQL_USER=crawler              # å»ºè®®ç”¨ä¸“ç”¨è´¦æˆ·
MYSQL_PASSWORD=your_secure_password
MYSQL_DATABASE=ip_pool

# ============ Redis é…ç½® ============
REDIS_HOST=192.168.1.101        # Redis æœåŠ¡å™¨åœ°å€
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=                 # å¦‚æœå¯ç”¨äº†è®¤è¯ï¼Œå¡«å…¥å¯†ç 

# ============ HTTP é…ç½® ============
HTTP_TIMEOUT=15
HTTP_RETRIES=2
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64)

# ============ æŠ“å–é…ç½® ============
SOURCE_WORKERS=3
VALIDATE_WORKERS=40

# ============ æ£€æŸ¥é…ç½® ============
CHECK_BATCH_SIZE=1000
CHECK_WORKERS=30
CHECK_RETRIES=3
CHECK_RETRY_DELAY=5
FAIL_WINDOW_HOURS=24
FAIL_THRESHOLD=5

# ============ æ—¥å¿—é…ç½® ============
LOG_LEVEL=INFO
LOG_FILE_PATH=/var/log/ip-crawler/audit.log
LOG_DB_WRITE_ENABLED=true
LOG_DB_MASK_SENSITIVE=true
LOG_FILE_MASK_SENSITIVE=false
LOG_DB_RETENTION_DAYS=30

# ============ åŠ¨æ€çˆ¬è™«é…ç½® ============
DYNAMIC_CRAWLER_ENABLED=true
MAX_PAGES=10
MAX_PAGES_NO_NEW_IP=3
PAGE_FETCH_TIMEOUT_SECONDS=30

# ============ LLM/AI é…ç½®ï¼ˆå¯é€‰ï¼‰============
# æ˜¯å¦å¯ç”¨ AI è¾…åŠ©è§£æ
USE_AI_FALLBACK=false

# LLM API é…ç½®ï¼ˆå¦‚éœ€ä½¿ç”¨ AI åŠŸèƒ½ï¼‰
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini
LLM_API_KEY=sk-your-api-key-here
LLM_TIMEOUT_SECONDS=30
LLM_MAX_RETRIES=3

# AI è§¦å‘æ¡ä»¶
AI_TRIGGER_ON_LOW_CONFIDENCE=true
AI_TRIGGER_ON_NO_TABLE=true
AI_TRIGGER_ON_FAILED_PARSE=true

# AI ç¼“å­˜å’Œæˆæœ¬æ§åˆ¶
AI_CACHE_ENABLED=true
AI_CACHE_TTL_HOURS=24
AI_COST_LIMIT_USD=1.0
```

**âš ï¸ LLM é…ç½®è¯´æ˜**ï¼š
- å¦‚ä¸ä½¿ç”¨ AI åŠŸèƒ½ï¼Œä¿æŒ `USE_AI_FALLBACK=false`
- æ”¯æŒ OpenAIã€Azure OpenAIã€æœ¬åœ° Ollama ç­‰å…¼å®¹ OpenAI API çš„æœåŠ¡
- `AI_COST_LIMIT_USD` ä¸ºå•æ¬¡ä¼šè¯æˆæœ¬ä¸Šé™ï¼Œé˜²æ­¢æ„å¤–è´¹ç”¨
- è¯¦è§ï¼š[LLM é›†æˆæŒ‡å—](./LLM_INTEGRATION.md)

âš ï¸ **å®‰å…¨å»ºè®®**ï¼š
- ä½¿ç”¨å¼ºå¯†ç 
- ä¸ºç¨‹åºåˆ›å»ºä¸“å†¶ MySQL è´¦æˆ·
- ä½¿ç”¨ç»å¯¹è·¯å¾„æŒ‡å®šæ—¥å¿—ç›®å½•
- é™åˆ¶ `.env` æ–‡ä»¶æƒé™ï¼š`chmod 600 .env`

### æ­¥éª¤ 4: éªŒè¯è¿æ¥

```bash
# æµ‹è¯• MySQL
mysql -h 192.168.1.100 -u crawler -p -e "SELECT VERSION();"

# æµ‹è¯• Redis
redis-cli -h 192.168.1.101 PING

# æµ‹è¯• Python è¿æ¥
python -c "
from crawler.config import Settings
from crawler.storage import get_mysql_connection, get_redis_client

settings = Settings.from_env()
mysql_conn = get_mysql_connection(settings)
print('âœ“ MySQL è¿æ¥æˆåŠŸ')

redis_client = get_redis_client(settings)
print('âœ“ Redis è¿æ¥æˆåŠŸ')
"
```

### æ­¥éª¤ 5: åˆå§‹åŒ–æ•°æ®åº“

ç¨‹åºä¼šè‡ªåŠ¨åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨ï¼Œé¦–æ¬¡è¿è¡Œæ—¶ï¼š

```bash
python cli.py run
```

**éªŒè¯åˆå§‹åŒ–**ï¼š
```sql
mysql> SHOW TABLES FROM ip_pool;
-- åº”è¿”å›ï¼šproxy_sources, proxy_ips, audit_logs ç­‰è¡¨
```

### æ­¥éª¤ 5.5: éƒ¨ç½²åéªŒè¯ï¼ˆè½»é‡ï¼‰

éƒ¨ç½²å®Œæˆåï¼Œå»ºè®®è¿è¡Œè½»é‡éªŒè¯è„šæœ¬ã€‚è¯¥è„šæœ¬åªå¯¹æ¯ä¸ªæºæŠ“å– 1 æ¡æ ·æœ¬å¹¶è¾“å‡ºéªŒè¯æŠ¥å‘Šï¼š

```bash
python cli.py verify-deploy
```

è¾“å‡ºæŠ¥å‘Šï¼š`reports/verify_report.md`ï¼ˆä¸­è‹±æ–‡åŒè¯­ï¼‰

**æ–‡æ¡£å¥åº·æ£€æŸ¥ï¼ˆå»ºè®®ï¼‰**ï¼š
```bash
python cli.py check-docs-links
```

ç”¨é€”ï¼š
- æœ¬åœ°å‘å¸ƒå‰æ£€æŸ¥æ–‡æ¡£é“¾æ¥
- CI ä¸­å¤ç”¨ï¼ˆåé“¾è¿”å›é 0 é€€å‡ºç ï¼Œå¯é˜»æ–­åˆå¹¶ï¼‰

**å¸¸è§æœªæŠ“å–æˆåŠŸåŸå› **ï¼š
- ç½‘ç»œä¸å¯è¾¾ / DNS è§£æå¤±è´¥
- ç›®æ ‡ç«™ç‚¹é™åˆ¶è®¿é—®ï¼ˆ403/429ï¼‰
- è¶…æ—¶æˆ– TLS æ¡æ‰‹å¤±è´¥
- ç«™ç‚¹ä¸´æ—¶æ•…éšœæˆ–è¿”å›ç©ºæ•°æ®

### æ­¥éª¤ 6: è®¾ç½®å®šæ—¶ä»»åŠ¡

#### Linux/Mac (Crontab)

```bash
# ç¼–è¾‘ crontab
crontab -e
```

æ·»åŠ ä»¥ä¸‹ä»»åŠ¡ï¼š

```cron
# æ¯å¤©å‡Œæ™¨ 3 ç‚¹è¿è¡Œçˆ¬è™«
0 3 * * * cd /path/to/ip-pool-crawler && python cli.py run >> /var/log/ip-crawler/cron.log 2>&1

# æ¯ 30 åˆ†é’Ÿè¿è¡Œä¸€æ¬¡æ£€æŸ¥
*/30 * * * * cd /path/to/ip-pool-crawler && python cli.py check >> /var/log/ip-crawler/cron.log 2>&1
```

**éªŒè¯ä»»åŠ¡**ï¼š
```bash
crontab -l
```

#### Windows (ä»»åŠ¡è®¡åˆ’)

1. æ‰“å¼€"ä»»åŠ¡è®¡åˆ’ç¨‹åº"ï¼ˆ`Win+R` â†’ `taskschd.msc`ï¼‰
2. å³é”®"ä»»åŠ¡è®¡åˆ’åº“" â†’ "åˆ›å»ºåŸºæœ¬ä»»åŠ¡"
3. é…ç½®ï¼š
   - **åç§°**ï¼šIP Pool Crawler - Run
   - **è§¦å‘å™¨**ï¼šæ¯å¤© 3:00 AM
   - **æ“ä½œ**ï¼š
     - ç¨‹åºï¼š`C:\Python310\python.exe`
     - å‚æ•°ï¼š`cli.py run`
     - å·¥ä½œç›®å½•ï¼š`C:\path\to\ip-pool-crawler`

4. åˆ›å»ºç¬¬äºŒä¸ªä»»åŠ¡ï¼ˆæ£€æŸ¥ï¼‰ï¼š
   - **åç§°**ï¼šIP Pool Crawler - Check
   - **è§¦å‘å™¨**ï¼šæ¯ 30 åˆ†é’Ÿ
   - å…¶ä»–é…ç½®ç›¸åŒ

### æ­¥éª¤ 7: æ—¥å¿—å’Œç›‘æ§ç›®å½•

```bash
# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p /var/log/ip-crawler

# è®¾ç½®æƒé™
chmod 755 /var/log/ip-crawler

# åˆ›å»ºæ—¥å¿—è½®è½¬é…ç½®ï¼ˆLinuxï¼‰
sudo tee /etc/logrotate.d/ip-crawler > /dev/null << EOF
/var/log/ip-crawler/*.log {
    daily
    rotate 30
    compress
    missingok
    notifempty
    create 0640 $(whoami) $(whoami)
}
EOF
```

---

## âœ… éƒ¨ç½²åéªŒè¯

### åŠŸèƒ½éªŒè¯

```bash
# 1. æµ‹è¯•çˆ¬è™«
python cli.py run

# é¢„æœŸï¼šæˆåŠŸè·å–ä»£ç†ï¼Œå†™å…¥ MySQL å’Œ Redis

# 2. æ£€æŸ¥æ•°æ®
mysql -u crawler -p ip_pool -e "SELECT COUNT(*) as proxy_count FROM proxy_ips;"
redis-cli ZCARD proxy:alive

# 3. è·å–ä»£ç†
python cli.py get-proxy --protocol http --count 3

# 4. Cron æ—¥å¿—æ£€æŸ¥
tail -20 /var/log/ip-crawler/cron.log
```

### æ€§èƒ½åŸºå‡†

**é¢„æœŸæ—¶é—´**ï¼š
- é¦–æ¬¡çˆ¬è™«ï¼š1-3 åˆ†é’Ÿï¼ˆåŒ…æ‹¬å»ºè¡¨ï¼‰
- åç»­çˆ¬è™«ï¼š2-5 åˆ†é’Ÿ
- æ£€æŸ¥ä»»åŠ¡ï¼š3-10 åˆ†é’Ÿ
- è·å–ä»£ç†ï¼š< 1 ç§’

**é¢„æœŸæ•°æ®**ï¼š
- æ€»ä»£ç†æ•°ï¼š500-1500
- å¯ç”¨ä»£ç†ï¼š50-200ï¼ˆ3-15%ï¼‰
- æ•°æ®åº“å¤§å°ï¼š10-50MB
- Redis å†…å­˜ï¼š5-20MB

### ç›‘æ§æŒ‡æ ‡

```sql
-- æ£€æŸ¥ä»£ç†ç»Ÿè®¡
SELECT 
    COUNT(*) as total,
    SUM(CASE WHEN is_alive=1 THEN 1 ELSE 0 END) as alive,
    SUM(CASE WHEN is_deleted=1 THEN 1 ELSE 0 END) as deleted
FROM proxy_ips;

-- æ£€æŸ¥æœ€åæ›´æ–°æ—¶é—´
SELECT MAX(updated_at) as last_update FROM proxy_ips;

-- æ£€æŸ¥æ—¥å¿—ç»Ÿè®¡
SELECT 
    DATE(created_at) as date,
    COUNT(*) as logs,
    SUM(CASE WHEN log_level='ERROR' THEN 1 ELSE 0 END) as errors
FROM audit_logs
GROUP BY DATE(created_at)
ORDER BY date DESC
LIMIT 7;
```

---

## ğŸ”’ å®‰å…¨åŠ å›º

### 1. MySQL å®‰å…¨

```sql
-- ä¸ºç¨‹åºåˆ›å»ºä¸“ç”¨è´¦æˆ·
CREATE USER 'crawler'@'127.0.0.1' IDENTIFIED BY 'strong_password';

-- æˆäºˆæœ€å°‘æƒé™
GRANT SELECT, INSERT, UPDATE, DELETE ON ip_pool.* TO 'crawler'@'127.0.0.1';
GRANT EVENT ON ip_pool.* TO 'crawler'@'127.0.0.1';  -- ç”¨äºæ—¥å¿—æ¸…ç†äº‹ä»¶

-- åˆ·æ–°æƒé™
FLUSH PRIVILEGES;

-- ç¦ç”¨è¿œç¨‹ root ç™»å½•
DELETE FROM mysql.user WHERE User='root' AND Host!='localhost';
```

### 2. Redis å®‰å…¨

```bash
# ç¼–è¾‘ redis.conf
# requirepass your_strong_password
# bind 127.0.0.1
# protected-mode yes

# é‡å¯ Redis
redis-cli SHUTDOWN
redis-server /etc/redis/redis.conf
```

### 3. æ–‡ä»¶æƒé™

```bash
# é™åˆ¶ .env æƒé™
chmod 600 .env

# æ—¥å¿—æ–‡ä»¶æƒé™
chmod 644 /var/log/ip-crawler/audit.log

# ä»£ç ç›®å½•æƒé™
chmod 755 /path/to/ip-pool-crawler
chmod 644 /path/to/ip-pool-crawler/*.py
```

### 4. é˜²ç«å¢™

```bash
# Linux (UFW)
sudo ufw allow 3306/tcp from 127.0.0.1  # MySQL
sudo ufw allow 6379/tcp from 127.0.0.1  # Redis
sudo ufw allow 80/tcp                   # HTTPï¼ˆå¦‚æœå¼€æ”¾ APIï¼‰
sudo ufw allow 443/tcp                  # HTTPS
```

---

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

### 1. æ“ä½œç›‘æ§

```bash
# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f /var/log/ip-crawler/audit.log

# æœç´¢é”™è¯¯
grep ERROR /var/log/ip-crawler/audit.log

# ç»Ÿè®¡æ¯æ—¥æ“ä½œ
grep "^202" /var/log/ip-crawler/audit.log | cut -d' ' -f1 | sort | uniq -c
```

### 2. æ•°æ®åº“ç›‘æ§

```sql
-- ç›‘æ§ä»£ç†æ± å¥åº·çŠ¶æ€
SELECT 
    CEIL(COUNT(*) / 1000) * 1000 as total_proxies,
    SUM(CASE WHEN is_alive=1 THEN 1 ELSE 0 END) as alive_proxies,
    ROUND(100 * SUM(CASE WHEN is_alive=1 THEN 1 ELSE 0 END) / COUNT(*), 2) as availability_rate
FROM proxy_ips;

-- ç›‘æ§è¿‘æœŸæ€§èƒ½
SELECT 
    AVG(duration_ms) as avg_duration_ms,
    MAX(duration_ms) as max_duration_ms,
    COUNT(*) as operations
FROM audit_logs
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 HOUR);

-- ç›‘æ§é”™è¯¯ç‡
SELECT 
    COUNT(*) as total_ops,
    SUM(CASE WHEN log_level='ERROR' THEN 1 ELSE 0 END) as error_count,
    ROUND(100 * SUM(CASE WHEN log_level='ERROR' THEN 1 ELSE 0 END) / COUNT(*), 2) as error_rate_pct
FROM audit_logs
WHERE created_at >= DATE_SUB(NOW(), INTERVAL 1 HOUR);
```

### 3. å‘Šè­¦è§„åˆ™

**å»ºè®®è®¾ç½®çš„å‘Šè­¦**ï¼š

| æŒ‡æ ‡ | é˜ˆå€¼ | ä¸¥é‡ç¨‹åº¦ |
|------|------|--------|
| é”™è¯¯ç‡ | > 5% | ğŸŸ  ä¸­ç­‰ |
| å¹³å‡å»¶è¿Ÿ | > 1000ms | ğŸŸ  ä¸­ç­‰ |
| å¯ç”¨ä»£ç†æ•° | < 50 | ğŸŸ¡ è½»å¾® |
| æ•°æ®åº“æ—¥å¿—å¤§å° | > 1GB | ğŸŸ¡ è½»å¾® |
| Cron ä»»åŠ¡å¤±è´¥ | ä»»ä½•å¤±è´¥ | ğŸ”´ é«˜ |

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. MySQL ä¼˜åŒ–

```sql
-- æ·»åŠ ç´¢å¼•
ALTER TABLE proxy_ips ADD INDEX idx_is_alive_created (is_alive, first_seen_at);
ALTER TABLE proxy_ips ADD INDEX idx_country_protocol (country, protocol);

-- æŸ¥è¯¢è®¡åˆ’åˆ†æ
EXPLAIN SELECT * FROM proxy_ips WHERE country='US' AND protocol='http' LIMIT 10;

-- è¡¨ä¼˜åŒ–
OPTIMIZE TABLE proxy_ips;
OPTIMIZE TABLE proxy_sources;
OPTIMIZE TABLE audit_logs;
```

### 2. Redis ä¼˜åŒ–

```bash
# è·å– Redis ç»Ÿè®¡
redis-cli INFO stats

# ç›‘æ§å†…å­˜
redis-cli INFO memory

# è®¾ç½®å†…å­˜ä¸Šé™
redis-cli CONFIG SET maxmemory 512mb

# è®¾ç½®è¿‡æœŸç­–ç•¥
redis-cli CONFIG SET maxmemory-policy allkeys-lru
```

### 3. åº”ç”¨ä¼˜åŒ–

```dotenv
# å¢åŠ å¹¶å‘ï¼ˆå¦‚æœæœåŠ¡å™¨è¶³å¤Ÿå¼ºå¤§ï¼‰
SOURCE_WORKERS=5
VALIDATE_WORKERS=60

# æˆ–é™ä½å¹¶å‘ï¼ˆå¦‚æœèµ„æºç´§å¼ ï¼‰
SOURCE_WORKERS=1
VALIDATE_WORKERS=20

# å¢åŠ  HTTP è¿æ¥æ± å¤§å°
HTTP_TIMEOUT=20
HTTP_RETRIES=2
```

---

## ğŸ”„ å‡çº§å’Œç»´æŠ¤

### å®šæœŸç»´æŠ¤ä»»åŠ¡

```bash
# æ¯å‘¨
# - æŸ¥çœ‹æ€§èƒ½æ—¥å¿—
# - æ£€æŸ¥é”™è¯¯ç‡
# - å¤‡ä»½æ•°æ®åº“

# æ¯æœˆ
# - æ¸…ç†è¿‡æœŸæ—¥å¿—
# - ä¼˜åŒ–è¡¨ç´¢å¼•
# - å¤‡ä»½å®Œæ•´æ•°æ®åº“

# æ¯å­£åº¦
# - æ£€æŸ¥ä»£ç†æºæ˜¯å¦å¤±æ•ˆ
# - æ›´æ–°ä¾èµ–
# - æ€§èƒ½åŸºå‡†æµ‹è¯•
```

### æ•°æ®å¤‡ä»½

```bash
# MySQL å¤‡ä»½
mysqldump -u crawler -p ip_pool > /backup/ip_pool_$(date +%Y%m%d).sql

# Redis å¤‡ä»½
redis-cli --rdb /backup/redis_$(date +%Y%m%d).rdb

# ä»£ç å¤‡ä»½
tar -czf /backup/ip-pool-crawler_$(date +%Y%m%d).tar.gz /path/to/ip-pool-crawler
```

### ç¾éš¾æ¢å¤

```bash
# æ¢å¤ MySQL
mysql -u crawler -p ip_pool < /backup/ip_pool_20260212.sql

# æ¢å¤ Redis
redis-cli SHUTDOWN
cp /backup/redis_20260212.rdb /var/lib/redis/dump.rdb
redis-server
```

---

## ğŸš¨ æ•…éšœå¤„ç†

### å¸¸è§æ•…éšœå“åº”

| æ•…éšœ | å½±å“ | æ¢å¤æ—¶é—´ | å¤„ç†æ–¹å¼ |
|------|------|--------|--------|
| MySQL å®•æœº | æ— æ³•å…¥åº“ | 1-5 åˆ†é’Ÿ | é‡å¯ MySQLï¼Œæ£€æŸ¥ç£ç›˜ |
| Redis å®•æœº | æ— æ³•è·å–ä»£ç† | 1-2 åˆ†é’Ÿ | é‡å¯ Redisï¼Œæ¸…ç†å†…å­˜ |
| ç½‘ç»œä¸­æ–­ | æ— æ³•æŠ“å– | å–å†³äºç½‘ç»œ | ç­‰å¾…ç½‘ç»œæ¢å¤ |
| ä»£ç†æºå¤±æ•ˆ | æ— æ–°ä»£ç† | éœ€è¦æ›´æ–°æº | æ›´æ¢æ•°æ®æºæˆ–ç­‰å¾…æºä¿®å¤ |
| ç£ç›˜æ»¡ | æ— æ³•å†™å…¥æ—¥å¿— | 30+ åˆ†é’Ÿ | æ¸…ç†æ—§æ—¥å¿—/æ‰©å®¹ |

---

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

- ğŸ“– æŸ¥çœ‹ [æ•…éšœæ’æŸ¥æŒ‡å—](./TROUBLESHOOTING.md)
- ğŸ” æŸ¥çœ‹ [å®¡è®¡æ—¥å¿—](./AUDIT_LOGGING.md)
- ğŸ’» æŸ¥çœ‹ [æ¶æ„è®¾è®¡](./ARCHITECTURE.md)

---

**ç›¸å…³æ–‡æ¡£**ï¼š
- ğŸ‘‰ [å¿«é€Ÿå¼€å§‹](./QUICK_START.md)
- ğŸ‘‰ [å‘½ä»¤è¡Œå‚è€ƒ](./CLI_REFERENCE.md)
- ğŸ‘‰ [å®¡è®¡æ—¥å¿—](./AUDIT_LOGGING.md)
